{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87bc7322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project Title: \"Predicting Customer Churn in a Telecom Company\"\n",
    "#Goal: Build a binary classifier to predict if a customer will leave (churn) based on features like tenure, plan type, and usage.\n",
    "#Challenge: Handle imbalanced classes and optimize precision/recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc573d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,TensorDataset,Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48d0975f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "(7032, 30)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "csv_path = \"csv/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "#print(df.head())\n",
    "#print(df.isnull().sum())\n",
    "#print(df.dtypes)\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df = df.dropna(subset=['TotalCharges'])\n",
    "df = df.drop('customerID', axis=1)\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "binary_cols = ['gender', 'Partner', 'Dependents', 'PaperlessBilling', 'PhoneService']\n",
    "\n",
    "for col in binary_cols:\n",
    "    df[col] = df[col].map({'Yes': 1, 'No': 0, 'Male': 1, 'Female': 0})\n",
    "multi_cat_cols = [\n",
    "    'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n",
    "    'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', \n",
    "    'Contract', 'PaymentMethod'\n",
    "]\n",
    "\n",
    "df = pd.get_dummies(df, columns=multi_cat_cols, drop_first=True)\n",
    "num_cols=['tenure','MonthlyCharges','TotalCharges']\n",
    "scaler=StandardScaler()\n",
    "df[num_cols]=scaler.fit_transform(df[num_cols])\n",
    "\n",
    "bool_cols = df.select_dtypes(include='bool').columns\n",
    "df[bool_cols] = df[bool_cols].astype('int64')\n",
    "X = df.drop('Churn', axis=1).values.astype('float32')\n",
    "y = df['Churn'].values.astype('float32')\n",
    "\n",
    "print(X.dtype)  # should print float32 now\n",
    "print(X.shape)  # (5625, 30) as before\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03096b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n",
      "(5625, 30)\n"
     ]
    }
   ],
   "source": [
    "X=df.drop('Churn',axis=1).values\n",
    "y=df['Churn'].values\n",
    "\n",
    "X_train,X_temp,y_train,y_temp=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)\n",
    "X_val,X_test,y_val,y_test=train_test_split(X_temp,y_temp,test_size=0.5,random_state=42,stratify=y_temp)\n",
    "print(X_train.dtype)\n",
    "print(X_train.dtype)  # should be float32\n",
    "print(X_train.shape)  # should be (samples, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c60c0047",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChurnDataset(Dataset):\n",
    "    def __init__(self,features,labels):\n",
    "        self.X=torch.tensor(features,dtype=torch.float32)\n",
    "        self.y=torch.tensor(labels,dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx],self.y[idx]\n",
    "\n",
    "train_dataset=ChurnDataset(X_train,y_train)\n",
    "val_dataset=ChurnDataset(X_val,y_val)\n",
    "test_dataset=ChurnDataset(X_test,y_test)\n",
    "\n",
    "train_loader=DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "val_loader=DataLoader(val_dataset,batch_size=64,shuffle=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "945f8688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7032, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f24758ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerChurn(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super().__init__()\n",
    "        self.fc1=nn.Linear(input_size,hidden_size)\n",
    "        self.Relu=nn.ReLU()\n",
    "        self.fc2=nn.Linear(hidden_size,output_size)\n",
    "    def forward(self,x):\n",
    "        out=self.fc1(x)\n",
    "        out=self.Relu(out)\n",
    "        out=self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7759476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CustomerChurn(30,16,1)\n",
    "criterion=nn.BCEWithLogitsLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f51c4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1,loss:0.4453841261565685\n",
      "epoch 2,loss:0.4308989965780215\n",
      "epoch 3,loss:0.4261187457225539\n",
      "epoch 4,loss:0.42378256944092835\n",
      "epoch 5,loss:0.42181059650399466\n",
      "epoch 6,loss:0.41966556960886175\n",
      "epoch 7,loss:0.41838105564767664\n",
      "epoch 8,loss:0.4172363540327007\n",
      "epoch 9,loss:0.4166714427146045\n",
      "epoch 10,loss:0.4159177043898539\n"
     ]
    }
   ],
   "source": [
    "num_epochs=10\n",
    "for epochs in range(num_epochs):\n",
    "    epoch_loss=0\n",
    "    for inputs,labels in train_loader:\n",
    "        labels=labels.unsqueeze(1)\n",
    "        outputs=model(inputs)\n",
    "        #output=outputs.unsqueeze(1)\n",
    "        #print(outputs.shape)\n",
    "        #print(labels.shape)\n",
    "        batch_loss=criterion(outputs,labels)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss+=batch_loss.item()\n",
    "    avg_train_loss=epoch_loss/len(train_loader)\n",
    "    print(f\"epoch {epochs+1},loss:{avg_train_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdc16aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Train Loss: 0.4159, Val Loss: 0.4504, Val Accuracy: 0.7937\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_loss=0\n",
    "correct=0\n",
    "total=0\n",
    "with torch.no_grad():\n",
    "    for val_inputs,val_labels in val_loader:\n",
    "        val_outputs=model(val_inputs)\n",
    "        val_labels=val_labels.unsqueeze(1)\n",
    "        #print(val_outputs.shape)\n",
    "        #print(val_labels.shape)\n",
    "        loss=criterion(val_outputs,val_labels)\n",
    "        val_loss+=loss.item()\n",
    "\n",
    "        preds=torch.sigmoid(val_outputs)\n",
    "        predicted=(preds>0.5).float()\n",
    "        correct+=(predicted==val_labels).sum().item()\n",
    "        total+=val_labels.size(0)\n",
    "\n",
    "avg_val_loss=val_loss/len(val_loader)\n",
    "val_accuracy=correct/total\n",
    "print(f\"Epoch {epochs+1}/{num_epochs} - \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, \"\n",
    "          f\"Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae4415f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8082\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        labels = labels.unsqueeze(1)\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.sigmoid(outputs)\n",
    "        predicted = (preds > 0.5).float()\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_accuracy = test_correct / total\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30e94db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"customer_churn_prediction.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvtorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
